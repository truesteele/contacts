<html>
<head>
  <title>Something Bigger Is Happening</title>
  <style>
    body {
      margin: 0 auto;
      width: 744px;
      font-family: Source Serif Pro, serif;
      line-height: 32px;
      font-weight: 400;
      color: rgba(0, 0, 0, 0.7);
      font-size: 21px;
    }
    h1, h2, h3 {
      font-family: Source Sans Pro, Helvetica, Arial, sans-serif;
    }
    h1 a, h1 a:visited {
      color: inherit;
      text-decoration: none;
    }
    h1 {
      line-height: 48px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 42px;
      margin: 32px 0 20px;
    }
    h2 {
      line-height: 32px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 26px;
      margin: 28px 0;
    }
    h3 {
      line-height: 28px;
      font-weight: 600;
      color: rgba(0, 0, 0, 0.85);
      font-size: 21px;
      margin: 24px 0;
    }
    p {
      margin: 32px 0;
    }
    .created, .published {
      color: rgba(0, 0, 0, 0.55);
      font-size: 15px;
      line-height: 15px;
      margin: 20px 0;
    }
    .created + .published {
      margin-top: -12px;
    }
    blockquote {
      font-family: Georgia, Source Serif Pro, serif;
      font-style: italic;
      font-size: 24px;
      line-height: 36px;
      margin: 48px 120px;
      text-align: center;
    }
    a {
      word-wrap: break-word;
      outline: none;
      text-decoration: none;
      background-color: transparent;
      border: 0;
      color: #008CC9;
    }
    a:hover {
      text-decoration: underline;
    }
    a:visited {
      color: #8C68CB;
    }
    .center {
      text-align: center;
    }
    iframe {
      display: block;
      margin: 44px auto;
    }
    *:not(pre) + pre, pre:first-of-type {
      margin-top: 32px;
      padding-top: 32px;
    }
    pre:only-of-type {
      margin: 32px 0;
      padding: 32px;
    }
    pre {
      background: #F3F6F8;
      overflow-x: auto;
      display: block;
      font-size: 13px;
      font-family: monospace;
      line-height: 13px;
      padding: 0 32px 32px;
      white-space: pre;
    }
    a.embedded {
      background: #F3F6F8;
      display: block;
      padding: 32px;
      margin: 32px 0;
    }
    img {
      height: auto;
      max-width: 100%;
    }
    .slate-image-embed__resize-full-width img {
      width: 100%;
    }
    .series-logo {
      width: 48px;
      height: 48px;
      box-sizing: border-box;
      background-clip: content-box;
      border: 4px solid transparent;
      border-radius: 6px;
      object-fit: scale-down;
      float: left;
    }
    .series-title {
      font-size: 16px;
      font-weight: 600;
      vertical-align: top;
    }
    .series-description {
      color: rgba(0,0,0,.6);
      font-weight: 400;
      font-size: 14px;
      line-height: 20px;
    }
    div {
      margin: 32px 0;
    }
  </style>
</head>
<body>
    <img class="series-logo" src="https://media.licdn.com/dms/image/v2/D5612AQGkGwRIaO67QA/series-logo_image-shrink_300_300/series-logo_image-shrink_300_300/0/1738831483659?e=1773273600&v=beta&t=UVbaRO8CYqDhUvnJvBJCDlOa538HbbReoWcKeoT2jZ8" />
    <h3>
      <span class="series-title">The Long Arc</span>
      </br>
      <span class="series-description">Monthly insights on transforming institutional power. For leaders navigating between market success and social impact.</span>
    </h3>
    <img src="https://media.licdn.com/mediaD5612AQGyNuXgB-ygdg" alt="" title="" />
      <h1><a href="https://www.linkedin.com/pulse/something-bigger-happening-justin-steele-vua6c">Something Bigger Is Happening</a></h1>
    <p class="created">Created on 2026-02-15 00:47</p>
  <p class="published">Published on 2026-02-17 16:00</p>
  <div><p>Think back to the summer of 2020.</p><p>Not to COVID. To what happened inside of it.</p><p>We'd been watching Black people die on camera for years. Eric Garner. Tamir. Alton. Philando. Each one a wave of outrage that crested and receded. Protests, then silence. Hashtags, then nothing. Like school shootings. Unbearable for a week, then absorbed into the background noise of American life. You'd feel it in your chest, and then you'd go back to work.</p><p>Then George Floyd.</p><p>Same violence. Same cameras. But something tipped. Maybe it was the length of that video. Maybe it was COVID locking everyone in their homes with nowhere to look away. Maybe it was nine minutes and twenty-nine seconds, long enough that you couldn't tell yourself this was a split-second mistake.</p><p>In Oakland, <a target="_blank">Sally Steele</a> and I walked our four daughters over to Park Boulevard. Hundreds of families were already there. We knelt together for eight minutes and forty-six seconds — the number the country was counting then. My oldest held my youngest. Nobody said a word. You could hear the birds.</p><p>Then everyone stood up. And the country erupted.</p><p>Not because the facts changed. Because something tipped, and people who'd been on the sidelines their whole lives stepped into the streets. Researchers at Harvard estimated that 15 to 26 million Americans protested that summer, quite possibly the largest protest movement in the country's history. It wasn't organized by one person or one institution. It was a force that had been building quietly for years until the moment it became unstoppable.</p><p>I'd spent the five years before that summer directing over $100 million in racial justice funding at Google, building partnerships with organizations like the Equal Justice Initiative after the Charleston church shooting, trying to meet each crisis with resources and infrastructure. I know what a tipping point feels like from the inside. I'm not comparing the stakes. I'm naming the pattern: when the people who've been sidelined step into their power, systems change. And I think we're in the early seconds of another one.</p><p>Not about racial justice directly. About who gets to build things. About who gets to create the tools that shape how we live. About a wall that has separated the people who understand problems from the people who build solutions for all of recorded history. The same question that drove those protests — who holds power, who gets to wield it, whose lives get shaped by decisions they had no hand in making — is now playing out in technology.</p><p>That wall just fell.</p><p>An essay called "Something Big Is Happening" went viral earlier this month. A tech founder named Matt Shumer wrote it as a letter to his friends and family. He compared this moment to February 2020, right before COVID changed everything. He said AI had quietly gotten so good that it could do his job, writing software, better than he could. He told people to start using AI or get left behind.</p><p>He's right that something big is happening. But he's telling a story about what AI takes away.</p><p>I need to tell you what AI gives. And I need to stop being polite about it.</p><hr><h3>Here's my confession</h3><p>I've been moving through my world, through nonprofit boardrooms and funder convenings and Oakland basement meetups, and dialing myself down.</p><p>I spend my days building AI-powered platforms. Coding until one or two in the morning. Shipping software over weekends. Building things in hours that would have required entire engineering teams two years ago. It feels like being in a nightclub at peak hour. Relentless. Electric.</p><p>Then I walk into social impact spaces, and it's like stumbling out of the nightclub into a library. My ears are still ringing. The beats still reverberating in my body. I'm bobbing to the music in my head as I walk through the doors. It's quiet. Folks are looking at me like I'm being disruptive. But I'm on a high. I start talking about how alive things are in the AI building space. My enthusiasm is real. People can see it. But they're not convinced. Not convinced they're invited to the party. Not convinced the tools are as capable as I say they are. They tried them a few months ago. Good but not great. Made mistakes. They're not coders, so they don't think they can code with them. You need a real developer.</p><p>So I dial it back. Match the room. Speak carefully.</p><p>"AI has some compelling applications for our sector."</p><p>"After you understand the potential harms, it's worth exploring."</p><p>"Start with low-risk personal use cases."</p><p>That's the polite version. The version that doesn't make people uncomfortable. When I talk at full volume about what I've seen, people look at me like I'm being naive. Like I don't understand the real constraints. Like I've been spending too much time in Silicon Valley and not enough time in the real world.</p><p>But I have four daughters. I live in Oakland. I spent nearly a decade inside Google directing $698 million in philanthropy to communities that were promised innovation would help them and then watched it mostly help the innovators instead. I know the real constraints. I've lived inside them.</p><p>And I'm telling you, from inside those constraints, that what is happening right now is not incremental. It's not hype. And the people I care about most are going to miss it if someone doesn't say this plainly.</p><p>So let me say it plainly.</p><hr><h3>Over a bag of fries</h3><p>Shumer's moment of truth came on February 5th, 2026. Two AI labs released new models and he realized AI could now do his entire job better than he could.</p><p>My moment started three years earlier. Over a bag of fries.</p><p>December 2022. Sally, the girls and I are driving home from Yosemite with <a target="_blank">michael mcbride</a> and his family. We've been dreaming about creating something to get more families like ours, from urban cities, into national parks and forests that feel like they belong to everyone but somehow don't feel like they belong to us.</p><p>On the drive, we try to name this thing. Rooted Outside. Nature Rhythms. Every good name is taken.</p><p>ChatGPT had been released to the public a few weeks earlier. We open the app and tell it what we're trying to build. At first it comes up with similar names as us. All taken. We stop at a Five Guys to grab lunch and keep prompting over a huge bag of fries and burgers while the kids climb over each other in the booth.</p><p>We ask it to combine two words into a new word, one that's not in the dictionary, that captures the spirit of what we're building.</p><p>Outdoor + Algorithm = <a target="_blank">Outdoorithm</a>. With a double meaning: finding your rhythm in the outdoors.</p><p>We know immediately. That's it. A Google search confirms zero results. We've just created something brand new in the world. We buy the domain on Squarespace before we get back on the highway. A week later, DALL-E creates our logo.</p><p>That was a name. A fun trick. A parlor game with a new tool. But it planted something.</p><p>Six months later, June 2023, I want to help our camping families understand what weather to expect at any campground, any time of year. I ask ChatGPT how. It recommends writing a Python script that pulls historical weather data from GPS coordinates.</p><p>I'd written C++ in engineering school twenty years earlier and built a basic website in HTML. But I'd never touched Python. Never built a real web application. Never written anything beyond homework assignments that ran in a terminal.</p><p>I ask ChatGPT how to install VS Code on my computer. I give myself one night.</p><p>Two hours of copying and pasting code from ChatGPT into this tool I haven't touched since college-era programming. I run the script. It spits out a file. I open it.</p><p>A perfect spreadsheet. Fifty-two weeks in rows. Average high temperature, low temperature, and chance of precipitation at Pfeiffer Big Sur State Park campground.</p><p>I jump out of my chair.</p><p>It's midnight. The house is quiet. Sally's working in the other room. The girls are asleep. And I'm standing in our Oakland living room staring at a screen, realizing that something fundamental just shifted.</p><p>That was June 2023. I haven't stopped building since.</p><hr><h3>The timeline nobody's talking about</h3><p>Shumer lays out the AI progression from the tech world. Here's a different one.</p><p><strong>2023–2024.</strong> I teach myself to build with AI, one project at a time. Copying code from ChatGPT, pasting it into VS Code, fixing what breaks, learning as I go. Interactive campground maps. Weather widgets. Backend data queries. Custom features for our community.</p><p><strong>September 2024.</strong> After nearly a decade at Google.org, my role is eliminated. One meeting and an unceremonious exit.</p><p><strong>Fall 2024.</strong> I discover Cursor, an AI coding environment that can read my entire codebase. Before this, I'd been copying and pasting code snippets into ChatGPT without the full context. As someone just learning to code with AI as a pair programmer, that was the hardest part — figuring out which pieces of my script were relevant for each new feature or bug fix. Cursor changed everything. It could see all of it. I use it to fully build out Outdoorithm's campground map: thousands of public campgrounds from a patchwork of county, state, and federal agencies, color-coded by sentiment, with information popups when you click the icons. The code for that map was too long to fit in a single context window before. Now I can build it in days.</p><p><strong>February 2025.</strong> 11 PM. Our small Oakland craftsman home. Sally is on the couch planning our nonprofit's winter camping trip to Muir Woods. Outdoorithm Collective's bank account: $33,000. The heaters we need for families camping in 45-degree weather: $9,480. I'm staring at 3,000 funder "matches" from a platform that costs $3,600 a year. Matches that would take a full-time person a year to sort through.</p><p>I pop open Cursor and build an AI system that thinks like a program officer instead of a search engine. I know how program officers think because I spent a decade as one. The AI evaluates each funder the way a real person would: reading about the organization, assessing fit intuitively, deciding whether to dig deeper or pass.</p><p>First pass: 90% of false positives eliminated. Three thousand matches become three hundred. Then one hundred fifty, stack-ranked by quality.</p><p>At the top: the George Family Foundation. Bill George was my professor at Harvard Business School. I'd been his student, his fellow, and I'd never connected his foundation's focus on whole-person wellbeing to our outdoor equity work. The AI found a strategic match I missed for years. Within twenty-four hours, we have a meeting with their Executive Director.</p><p><strong>March 2025.</strong> My friend <a target="_blank">Karibu Nyaggah</a>, a bond forged twenty years earlier at Harvard, Google colleague, now at Meta, calls me from his kitchen island in Half Moon Bay. Three hours later, we're co-founders. We call it Proxi at first, later <a target="_blank">Kindora</a>. In April, we hire a senior full-stack developer to help take our prototype into production. $6,500 a month, out of our own pockets. At that point, AI models couldn't quite take you all the way to production-grade software. You still needed a professional developer to close the gap. Progress is steady but slow.</p><p><strong>August 2025.</strong> We incorporate Kindora as a Public Benefit Corporation, launch our beta, and I start using Claude Code, Anthropic's command-line coding tool. Another leap. I prompt it in plain language from my terminal and it builds across my entire codebase. The first weekend, I ship an analytics dashboard, email automation for the flood of beta users, a feedback system, and support ticketing. Part-time. That's work that would have taken our developer multiple weeks. Same team, ten times the output. Not because we worked harder, but because the tools had changed underneath us.</p><p><strong>December 2025.</strong> We end our developer contract. Three years of building with AI had converged with the release of Claude's Opus 4.5 model in November. Anthropic's own engineers were building entire codebases with Claude. I found I could do the same. The gap that required a professional developer nine months earlier had closed completely.</p><p><strong>By early 2026.</strong> Outdoorithm and Kindora are both production platforms serving hundreds of organizations — campground discovery, AI trip planning, funder matching across 175,000 foundations, grant intelligence, federal grants pipeline. I built both. I also build AI products for clients through my consulting practice.</p><p><strong>Last week.</strong> I built a virtual voice AI assistant that simulates a funder conversation so nonprofits can practice their pitch before a real meeting. Four prompts. One night. Working prototype.</p><p>I'm 43 years old. I have four daughters, ages 4 to 16. I have degrees in chemical engineering, business, and policy. Three years ago, I had never written a Python script or built a web application. I now run technology ventures, ship production software, and build AI tools that serve hundreds of organizations.</p><p>If you think that story is about me being uniquely talented, you've missed the entire point.</p><hr><h3>The wall between knowing and building</h3><p>Shumer's essay tells a displacement story. AI is replacing human work. His job got automated. Yours is next. Learn AI or get left behind.</p><p>I'm living the other side of that story.</p><p>For as long as anyone can remember, there's been a wall between the people who understand problems and the people who can build solutions. On one side: the social worker who's watched families fall through intake cracks for fifteen years. The teacher who knows exactly why her students are struggling. The environmental justice organizer who sees patterns in pollution data that researchers miss. The restaurant owner on Foothill Boulevard in Deep East Oakland who can barely pay her electric bill and sits in a breakout room at the mayor's economic forum asking, "Where's that $100 million?" because the investment that was supposed to revitalize her corridor never reached her.</p><p>On the other side of that wall: the engineers. The people who could build software, tools, and systems but who've never met the families, never walked the corridors, never sat across from someone choosing between paying PG&amp;E and buying groceries.</p><p>That wall is gone.</p><p>Shumer proves it from one direction. AI can now do what developers do. I'm proving it from the other. People who were never developers can now build. Both of those things are true. But only one of them changes who holds power.</p><p>When everyone can build, the differentiator shifts. It's no longer about technical execution. It's about knowing which problems matter and what good solutions look like. Call it taste. Not taste as aesthetics. Taste as the deep, earned understanding that comes from fifteen years in the field, from proximity to real communities, from doing the work.</p><p>Here's what taste looks like. Outdoorithm, the camping platform Sally and I built, has a feature called The Green Book. Named after the historic Negro Motorist Green Book that helped Black travelers find safe places during Jim Crow. Our version uses AI to analyze 1.85 million campground reviews for discrimination, safety concerns, and community atmosphere, then flags which campgrounds are welcoming for families of color, LGBTQ+ travelers, and solo women. No engineering team at a camping startup would think to build that. I built it because I've been the dad loading four daughters into the car wondering if the campground is going to feel like it belongs to us.</p><p>That's what taste is. The lived experience that tells you what to build when the tools finally let you build it.</p><p>For decades, Silicon Valley's advantage was that they knew how to build. The domain experts knew what needed to exist but couldn't create it. That asymmetry kept power exactly where it was.</p><p>It's collapsing. Right now.</p><hr><h3>"You mean Claude can build that for you"</h3><p>Last week I was at the Camelback Ventures accelerator with a cohort of founders building in education and social impact. We did a "reciprocity ring" exercise where each person wrote down what support they need and what they can offer.</p><p>Brianna Baker, the founder of Justice for Black Girls, wrote that she needs help building a tech platform to connect her research fellows with the seventy-five members of their Academic Network. Scheduling, automation, follow-up emails, connections between aligned research.</p><p>I tapped her at the table next to mine and told her I can build it.</p><p>Another fellow at the table chuckled. "You mean Claude can build that <em>for</em> you."</p><p>As if that made it less real. As if my ability to understand what Brianna actually needs, to translate her vision into the right architecture, to exercise judgment about what matters, wasn't the hard part. As if the only "real" way to build software is to type every character yourself.</p><p>That sentiment is everywhere in my spaces. And it's leaving us behind.</p><p>EdTech founders at the same program told me their software needs to be airtight for school districts. No security risks, no authentication errors. They think AI-generated code can't get there. I understand the instinct. Six months ago, they may have been right. But right now, Anthropic's own team is publishing what this looks like in practice — agent teams building real systems inside shared codebases with Claude Code. According to YC managing partner Jared Friedman, about a quarter of YC's Winter 2025 batch had codebases that were roughly 95% AI-generated. The gap between "AI-built" and "production-grade" has closed faster than anyone predicted.</p><p>In my world, the objection goes deeper than "AI isn't good enough yet." It's "I'm not technical." It's "We need a real developer." It's "This isn't for people like us." If you've heard that last one before, it's because it's the same voice that's been gatekeeping every corridor of power for generations. Who gets to build, who gets funded, who gets to walk into the room and be taken seriously — it's the same fight wearing new clothes.</p><p>That belief is the most expensive thing you will ever hold.</p><p>Not because AI is coming for your job. Because AI is handing you the power to build solutions for the problems you've spent your career understanding, and you're looking at those tools and saying "not for me."</p><hr><h3>What I haven't been saying loudly enough</h3><p>I've been careful in my spaces. Measured. Polite. Matching the tenor of the room.</p><p>The thing keeping your communities stuck, the grant prospecting that takes months, the reporting that consumes 40% of your staff's time, the program evaluation you can't afford, the technology platform you need but can't build, AI can address much of that. Not in five years. Now. Today.</p><p>And the thing you've been told you lack, the technical skill, the engineering talent, that stopped being the bottleneck. The bottleneck is now something you have in abundance: deep knowledge of the problems worth solving. The instinct to know what a good solution actually looks like, earned over years of proximity to the people you serve.</p><p>The social worker. The teacher. The community organizer. The nonprofit founder with $33,000 in the bank. You were always the ones who understood the problems best. Now you can build the solutions too.</p><p>That's what's actually big about this moment. Not that AI replaces workers. That AI hands the tools to people who were never given permission to build.</p><hr><h3>The urgency is real</h3><p>But here's where I agree with Shumer completely.</p><p>Right now, the future of AI is being decided by the few hundred researchers Shumer describes, at a handful of companies, building tools that reflect their world. Every month that passes without domain experts in the room is a month the architecture gets built without their values, their knowledge, their priorities.</p><p>I watched this from inside Google for nearly a decade. The hardest lesson I learned is that values retrofitted after systems are built rarely stick, and even when they are established, they're often washed away by the pressures of the business. The same pattern I'd seen in criminal justice, in education, in economic development: by the time the people closest to the problem get a seat at the table, the architecture is already built.</p><p>Right now there is a window. The tools are accessible. The cost of building has collapsed. A single person with deep knowledge and AI tools can create in weeks what used to require a team of eight, nine months, and hundreds of thousands of dollars. That's not a prediction. That's my actual life.</p><p>If the people closest to the hardest problems step through this window and build, we get a different future. One where AI serves communities and not just shareholders. Where the tools reflect the values of the people who use them.</p><p>If they don't, the window closes. And someone else builds the future for them. Again.</p><p>Think about Park Boulevard. Families on their knees in the street. Fifteen to twenty-six million people stepped into the streets that summer. Not because the facts of racial injustice were new. Because a moment arrived when stepping in felt necessary. When standing on the sideline stopped being a defensible position.</p><p>This is that kind of moment for building.</p><p>But I won't lie to you about what it takes.</p><hr><h3>The moat called capital</h3><p>The technical wall fell. But there's still a moat, and it's called capital.</p><p>Kindora cost about $70,000 to build and launch. Outdoorithm was around $100,000. Those numbers are a fraction of what it used to cost to start a technology company. Two years ago, this work would have required a team of engineers and half a million dollars or more. AI collapsed the cost by 80 or 90 percent.</p><p>But $70,000 is still $70,000. And if you're a Black founder, a Latina founder, a first-generation founder whose parents didn't own property, that money doesn't materialize from a "friends and family round." Friends and family rounds work when your friends and family have wealth. When they don't, you're stuck before you start. The racial wealth gap doesn't pause because the cost of building software went down.</p><p>We floated credit card balances to keep Outdoorithm Collective running. Sally and I put $50,000 of personal money into equipment and operations before we paid ourselves a cent. We could do that because we had savings from years of professional-class salaries. Most of the founders I know who are closest to the hardest problems don't have that cushion.</p><p>So when I say the wall fell, I mean it. When I say anyone can build, I believe it. But "anyone can build" and "anyone can sustain what they build" are two different statements. The second one requires capital. And right now, capital is still flowing to the same places it always has.</p><p>We've seen this before. After Floyd, corporations pledged $50 billion toward racial equity. Foundations opened emergency funds. A lot of it evaporated or flowed to the same institutions that always get funded. Some capital managed to reach the builders closest to the problems, but the latest backlash largely erased what was gained. Now there's a new opening — the cost of building has collapsed, and domain experts can finally create their own solutions. But it will end the same way if capital doesn't follow.</p><p>This is where funders, foundations, and high-capacity individuals have to step up. Not with another report on AI's potential. With money. Foundations sitting on endowments should be opening them not just for impact investments but for venture investments in the builders closest to the problems. Individuals with means should be pooling capital into funds that back $1-5 million sustainable ventures serving real communities, not just billion-dollar unicorn bets. The incredible things our communities are capable of building won't survive without oxygen. Capital is that oxygen.</p><p>The cost of building just dropped by an order of magnitude. If we can't figure out how to get $50,000 to $100,000 into the hands of domain experts with working prototypes, we will have wasted the most democratizing technological shift of our lifetimes.</p><hr><h3>What I'd do this week</h3><p>Shumer tells people to pay $20 a month for AI and spend an hour a day experimenting. Good advice. Here's mine, for the communities his essay didn't mention.</p><p><strong>If you lead a nonprofit:</strong> Open Claude or ChatGPT this week. Not to explore. To solve one specific problem that eats your time. Feed it your last grant application and ask it to find the weaknesses. Give it your funder list and ask it to rank by fit. Start with the thing that overwhelms you most and see what happens. Prototype fast — but if you work with sensitive data, scrub it or use approved tools the same way you would with any other vendor.</p><p><strong>If you're a funder:</strong> Stop treating technology as overhead. Every nonprofit you fund without funding their ability to use these tools is an organization you're funding to fall behind. Put AI capacity in the next grant cycle. Not as a special initiative. As a standard expectation. And fund the builders creating AI for communities, not just the companies building AI for profit. Consider giving startup grants or investments, not just traditional charity.</p><p><strong>If you've been told you're "not technical":</strong> Let go of that identity. I had a C++ class in 2002 and hadn't written real code since. Last week I built a voice AI assistant in four prompts. You don't need to become a developer. You need to become a builder. Someone who knows what to create and can direct AI to create it. Those are different skills. You already have the hard one.</p><p><strong>If you have deep expertise in any problem:</strong> That expertise just became the most valuable asset in the room. Not because of what you know about AI. Because of what you know about your domain that AI doesn't. The school district. The housing system. The neighborhood. The families. That knowledge, combined with AI building tools, makes you more powerful than a team of developers who've never met the people you serve. Stop waiting for someone technical to build your solution. Start describing it to Claude and see what comes back.</p><p><strong>If you're raising kids:</strong> Shumer says rethink what you're telling your children. My daughters are 4, 12, 14, and 16. Here's what I'm telling them: Don't just learn how to use AI. Learn how to develop judgment about what's worth building and who it should serve. Study problems that move you. Get close to communities. The technical skills to build things will keep getting cheaper. The wisdom to know which things are worth building will only get more valuable. Become leaders of character who know how to connect with people deeply.</p><hr><p>Sometimes I hold back because I wonder if maybe I'm different. Maybe my fancy degrees or Google experience give me an unfair advantage that makes this work for me but wouldn't for others.</p><p>Then I build a voice AI assistant in four prompts and I think: there's no way I'm the only person who can do this.</p><p>I'm not. And neither are you.</p><p>On Park Boulevard that day in 2020, nobody was polite. Nobody was measured. Nobody was matching the tenor of the room. People were on their knees in the street with their children because a moment had arrived that demanded something more than caution.</p><p>The wall is down. I'm done being polite about this. The people I care about deserve to hear it at full volume.</p><p>What's the problem in your community you'd build a tool for — if you believed you were allowed to?</p><p>Share this with the smartest person you know who's been told they're "not technical enough." They might be the most important builder of the next decade. And they need to hear that the wall just came down, before someone else builds the future without them.</p><hr><p><em>Justin Steele is Co-Founder and CEO of Kindora, a Public Benefit Corporation using AI to help nonprofits find and win grants. He previously directed $698 million in philanthropy at Google.org over nearly a decade. He serves as a trustee at The San Francisco Foundation and as a fractional Chief Impact Officer through True Steele LLC where he has started building technology for others. He co-founded Outdoorithm Collective with his wife Sally, organizing group camping trips for urban families. He lives in Oakland with Sally and their four daughters.</em></p></div>
</body>
</html>