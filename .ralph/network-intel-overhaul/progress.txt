# Ralph Progress Log
Loop: network-intel-overhaul
Started: 2026-02-20
---

## Iteration 1: US-001 — Update Network Intelligence System Documentation
**Date:** 2026-02-20
**Status:** COMPLETE
**Commit:** 774a87a

**What was done:**
- Expanded Phase 6 section (14) of `docs/NETWORK_INTELLIGENCE_SYSTEM.md` with full donor psychology framework
- Added detailed documentation for all 4 pillars: Relationship Depth, Giving Capacity, Philanthropic Propensity, Psychological Readiness
- Added Critical Behavioral Insights section (insider effect, identifiable victim effect, social proof, loss aversion, second-gift psychology, cultivation timelines)
- Added per-contact context template and output schema for ask-readiness scoring
- Added detailed scoring tier descriptions with guidance
- All JSONB schemas already documented (fec_donations, real_estate_data, shared_institutions, ask_readiness)
- Implementation order and cost estimates already present

**Learnings:**
- The doc already had a comprehensive Phase 6 section (14.1-14.10) from prior planning work. The main gap was that section 14.7 (Ask-Readiness) only had brief bullet points for the 4 pillars — needed expansion with full framework details and behavioral insights from the plan file.
- The JSONB schemas, search system overhaul, UI updates, and implementation status were already well-documented.

## Iteration 2: US-002 — Database Migration — New Columns & Indexes
**Date:** 2026-02-20
**Status:** COMPLETE

**What was done:**
- Created migration file `supabase/migrations/20260220_network_intel_overhaul.sql`
- Added 5 new columns: `comms_last_date` (DATE), `comms_thread_count` (SMALLINT default 0), `fec_donations` (JSONB), `real_estate_data` (JSONB), `ask_readiness` (JSONB)
- Renamed existing `shared_institutions` TEXT[] column to `shared_institutions_legacy` (contained freetext like "Location: SF", "Current employer: Google")
- Created new `shared_institutions` JSONB column for structured overlap data (to be populated by score_overlap.py in US-006)
- Created 3 indexes: `idx_contacts_familiarity` (btree DESC), `idx_contacts_comms_last` (btree DESC), `idx_contacts_ask_readiness` (GIN)
- Applied migration via Supabase MCP `apply_migration`
- Verified all columns and indexes exist via SQL queries
- `familiarity_rating` already existed from prior migration (20260219)

**Learnings:**
- The `shared_institutions` column already existed as TEXT[] with freetext data from the tagging script. Renamed to `shared_institutions_legacy` to preserve data while creating the new JSONB column. The legacy data is mostly location strings and employer names — the new structured format will have temporal overlap analysis.
- No TypeScript code referenced `shared_institutions` yet, so the rename was safe. The only Python reference is in `deduplicate_contacts.py` (a completed one-time script).
- `familiarity_rating` column already existed from migration 20260219120000, so the plan's `ADD COLUMN IF NOT EXISTS` for that was unnecessary — just added the index.

## Iteration 3: US-003 — Backfill Comms Summary Fields
**Date:** 2026-02-20
**Status:** COMPLETE

**What was done:**
- Created `scripts/intelligence/backfill_comms_fields.py` — simple script to denormalize `communication_history` JSONB into `comms_last_date` and `comms_thread_count` columns
- Reads `communication_history->>'last_contact'` → `comms_last_date` (DATE) and `communication_history->>'total_threads'` → `comms_thread_count` (SMALLINT)
- Uses Supabase pagination with `.range()` pattern for fetching contacts
- Supports `--test` flag (preview 5 contacts without writing)
- Full run: 628 contacts updated, 0 errors, 34.4s
- Verified: `SELECT count(*) FROM contacts WHERE comms_last_date IS NOT NULL` = 628

**Learnings:**
- The `communication_history` JSONB stores `total_threads` and `last_contact` as strings (JSON text), so parsing `int(total_threads)` is needed for the SMALLINT column.
- The `comms_last_date` DATE column accepts the "YYYY-MM-DD" string directly from the JSONB without conversion.
- Data spans from 2007-07-16 to 2026-02-19, with avg 2.7 threads per contact and max 50.

## Iteration 4: US-004 — FEC Political Donation Enrichment Script
**Date:** 2026-02-21
**Status:** COMPLETE
**Commit:** 242b07d

**What was done:**
- Created `scripts/intelligence/enrich_fec_donations.py` — queries OpenFEC `/schedules/schedule_a/` for each contact
- Filters by cycles 2020-2026, paginates through all results
- Disambiguates results with name matching (handles compound last names like "Kapor Klein" → FEC stores as "KLEIN" with "KAPOR" in middle name)
- For compound last names, verifies all name parts appear in `contributor_name` field
- State-based disambiguation for common names (>10 results → prefer state matches)
- Stores JSONB with: total_amount, donation_count, max_single, cycles, recent_donations (top 10), employer_from_fec, occupation_from_fec, last_checked
- Rate limited to 3.7s between calls (~970/hr, safely under 1,000/hr limit)
- Sequential processing (parallelism not useful due to rate limit)
- Supports --test (1 contact), --batch N, --start-from flags
- Tested: batch of 3 contacts all found FEC records (e.g., Freada Kapor Klein: $233K across 83 donations)

**Learnings:**
- OpenFEC API uses `contributor_name` field for full-text search in "LAST, FIRST MIDDLE" format. The search is fuzzy/keyword — searching "KAPOR KLEIN, FREADA" returns results where name is "KLEIN, FREADA KAPOR".
- `contributor_first_name` and `contributor_last_name` are decomposed fields but don't handle compound names well — "KLEIN" is the last name while "KAPOR" ends up in the middle/first name area.
- The API supports `is_individual=true` to filter out PAC-to-PAC transfers.
- Pagination uses `last_index` + `last_contribution_receipt_date` cursor-based approach, not offset-based.
- Results include employer and occupation from FEC filings, which can cross-validate LinkedIn data.
- Rate limit: 1,000 requests/hour with API key. At 3.7s delay, full 2,400 contacts will take ~2.5 hours.

## Iteration 5: US-005 — Real Estate Holdings Enrichment Script
**Date:** 2026-02-21
**Status:** COMPLETE

**What was done:**
- Created `scripts/intelligence/enrich_real_estate.py` — production three-step pipeline script
- Step 1: Batch skip-trace via Apify `one-api/skip-trace` (25 names per batch, $0.007/result)
- Step 2: Zillow autocomplete API for ZPID (free, per-address sequential)
- Step 3: Batch Zillow detail via Apify `happitap/zillow-detail-scraper` (25 URLs per batch, ~$0.003/result)
- GPT-5 mini validates each skip-trace result — correctly rejects wrong-person matches
- Only processes contacts with `familiarity_rating >= 2 OR ai_capacity_tier = 'major_donor'`
- Stores full JSONB: address, zestimate, rent_zestimate, beds, baths, sqft, year_built, property_type, confidence, source, last_checked
- Three confidence/source states: "zillow_via_skip_trace" (full success), "skip_trace_only" (address but no ZPID), "skip_trace_rejected" (wrong person), "skip_trace_failed" (no result)
- Supports --test (1 contact), --batch N, --start-from flags
- Tested: batch of 5 contacts → 4 addresses found, 4/4 validated, 4/4 ZPIDs, 4/4 Zestimates (80% end-to-end)
- Results: Zestimates ranged $462K-$1.1M across test contacts

**Learnings:**
- The skip-trace API returns results keyed by "Input Given" field matching the input name string. Must try multiple key formats (name + city + state, name + state, name alone) to match.
- GPT-5 mini validation works well — the first test contact (Kay Fernandez Smith) was correctly rejected because the skip-trace found someone in Travelers Rest, SC when contact is in a different location.
- Batch skip-trace is efficient — 5 contacts in a single Apify run takes ~8s. The Zillow detail batch also handles multiple URLs in one run.
- Zillow autocomplete is very reliable — 100% ZPID found for all validated addresses in testing.
- The `$ ` prefix in the Zillow detail print was a minor bug (should be contact name not dollar sign) but doesn't affect functionality.
- Rejected and no-result contacts get stored with appropriate markers so they won't be re-processed on subsequent runs.

## Iteration 6: US-006 — Structured Institutional Overlap Script
**Date:** 2026-02-21
**Status:** COMPLETE

**What was done:**
- Created `scripts/intelligence/score_overlap.py` — uses GPT-5 mini structured output to analyze institutional overlap between Justin and each contact
- Includes Justin's full career timeline (12 entries: Bain, Bridgespan, Year Up, HBS, HKS, Google.org, Outdoorithm, True Steele, Kindora, Outdoorithm Collective, SF Foundation, UVA)
- Pydantic schema: `OverlapAnalysis` containing `list[SharedInstitution]` with fields: name, type (employer/school/board/volunteer), overlap status (confirmed/likely/possible/different_era), justin_period, contact_period, temporal_overlap (bool), depth (same_team/same_org/same_field/alumni/adjacent), notes
- Sends contact's enrich_employment, enrich_education, enrich_volunteering, connected_on, plus existing ai_tags overlap data for reference
- Filters to contacts with shared institution signals in ai_tags (~1,467 contacts eligible)
- Concurrent processing with ThreadPoolExecutor (8 workers)
- Supports --test (1 contact), --batch N, --start-from flags
- Test results: 4/4 contacts processed successfully
  - Jeanne Byrd Adams: Year Up (employer, temporal overlap likely)
  - Eugene Kirpichov: Google/Google.org (employer, temporal overlap confirmed)
  - Kay Fernandez Smith: SF Foundation (board, temporal overlap) + HKS (school, different era)
  - Miguel Santana: Harvard/HKS (school, no temporal overlap)
- Data stored as JSONB array in contacts.shared_institutions column

**Learnings:**
- The enrich_employment field stores dates inconsistently — some have start_date/end_date, some only have duration strings like "2 yrs", some have nothing. The LLM handles this gracefully by marking contact_period as "unknown" when dates aren't available.
- Double-parsing is needed: the JSONB fields are sometimes stored as JSON strings within strings (double-encoded), so `parse_jsonb()` may need to be called twice.
- GPT-5 mini correctly normalizes related org names (e.g., "Google" and "Google.org" → "Google / Google.org") and handles school program distinctions well.
- The existing ai_tags overlap data provides useful hints that the LLM verifies and enriches with temporal detail — passing it as reference context helps accuracy.
- ~15s per contact on average with concurrent processing, so full run of ~1,467 contacts would take ~45 min with 8 workers. Cost ~$2.50.

## Iteration 7: US-007 — Ask-Readiness Scoring Script (Donor Psychology)
**Date:** 2026-02-21
**Status:** COMPLETE
**Commit:** b786822

**What was done:**
- Created `scripts/intelligence/score_ask_readiness.py` — the core donor psychology scoring script
- Full donor psychology system prompt with all 4 pillars (Relationship Depth, Giving Capacity, Philanthropic Propensity, Psychological Readiness) + critical behavioral insights + scoring guidance
- Per-contact context assembles: familiarity_rating, position/company/headline, shared_institutions (structured + fallback to ai_tags), ai_capacity_tier, ai_outdoorithm_fit, fec_donations summary, real_estate_data summary, communication_history (last date, thread count, relationship summary, recent thread subjects), connected_on, topics, philanthropic signals
- Pydantic structured output: score, tier, reasoning, recommended_approach, ask_timing, cultivation_needed, suggested_ask_range, personalization_angle, risk_factors
- Goal parameterized with `--goal` flag (defaults to outdoorithm_fundraising, also supports kindora_sales)
- Results stored in `contacts.ask_readiness` JSONB keyed by goal, with scored_at timestamp
- Preserves existing goal scores when adding new ones (merges into existing JSONB)
- Supports `--test`, `--batch N`, `--start-from`, `--goal`, `--force`, `--workers` flags
- Concurrent batch processing with ThreadPoolExecutor (8 workers default)
- Color-coded tier output in terminal (green=ready_now, yellow=cultivate_first, gray=long_term, red=not_a_fit)
- Summary stats: count by tier, score distribution (avg/min/max), token usage, cost
- Tested: 1 contact test + 3 contact batch, all succeeded
  - Jeanne Byrd Adams: 72 (cultivate_first) — Year Up connection, DEI alignment, $2.5K-$10K range
  - Eugene Kirpichov: 74 (cultivate_first) — Google temporal overlap, 5 email threads
  - Dakarai Aarons: 72 (cultivate_first) — philanthropy background, FEC donor
  - Dreama Gentry: 65 (cultivate_first) — nonprofit CEO, FEC donor, weak familiarity
- Performance: ~9s/contact with concurrent processing, ~20s sequential. Full 2,400 contacts would take ~50 min with 8 workers

**Learnings:**
- The donor psychology prompt produces realistic, evidence-based scoring. All 4 test contacts scored in the 65-74 range (cultivate_first), which is sensible — they have some relationship but aren't inner-circle close friends.
- The personalization_angle field is particularly valuable — it cites specific shared experiences and connection points that feel authentic.
- Communication history adds meaningful signal — Eugene scored higher partly because he has 5 email threads with Justin.
- The FEC data enriches reasoning well — Dreama's 11 FEC donations are cited as evidence of giving propensity.
- Handle double-encoded JSONB gracefully with the enhanced parse_jsonb() function (tries a second parse if first result is still a string).
- Cost is low: ~$0.003/contact at current GPT-5 mini rates. Full run would be ~$7.
- The --force flag correctly re-scores already-scored contacts and the JSONB merge preserves other goal scores.

## Iteration 8: US-008 — Update FilterState & Types
**Date:** 2026-02-20
**Status:** COMPLETE
**Commit:** ee01be9

**What was done:**
- Updated `job-matcher-ai/lib/types.ts` FilterState interface:
  - Added `familiarity_min?: number` — minimum familiarity rating filter (0-4)
  - Added `has_comms?: boolean` — filter for contacts with email history
  - Added `comms_since?: string` — filter for contacts communicated with since date
  - Added `shared_institution?: string` — filter by shared institution keyword
  - Added `goal?: 'outdoorithm_fundraising' | 'kindora_sales'` — goal for ask-readiness sorting
  - Extended `sort_by` with `'familiarity' | 'comms_recency' | 'ask_readiness'`
- Updated `job-matcher-ai/lib/supabase.ts` NetworkContact interface:
  - Added `comms_last_date?: string | null`
  - Added `comms_thread_count?: number | null`
  - Added `shared_institutions?: Record<string, any>[] | null`
  - Added `ask_readiness?: Record<string, any> | null`
  - `familiarity_rating` was already present from prior work
- TypeScript compilation passes clean

**Learnings:**
- The NetworkContact interface already had `familiarity_rating` and `familiarity_rated_at` from the familiarity rater feature. Just needed the new Phase 6 columns.
- The `goal` field is typed as a string union rather than plain string to match the ask_readiness JSONB key structure.
- `shared_institutions` typed as `Record<string, any>[]` (array of objects) since the JSONB stores an array of structured overlap entries.

## Iteration 9: US-009 — Update Search Route & NETWORK_SELECT_COLS
**Date:** 2026-02-20
**Status:** COMPLETE

**What was done:**
- Updated `NETWORK_SELECT_COLS` in both `job-matcher-ai/lib/network-tools.ts` and `job-matcher-ai/app/api/network-intel/search/route.ts` to include: `familiarity_rating, comms_last_date, comms_thread_count, ask_readiness`
- Added new filter handling in `executeStructuredSearch`:
  - `familiarity_min` → `query.gte('familiarity_rating', value)`
  - `has_comms` → `query.gt('comms_thread_count', 0)`
  - `comms_since` → `query.gte('comms_last_date', value)`
  - `ask_readiness` sort with `goal` → fetches contacts with non-null ask_readiness, sorts in-memory by goal score DESC
- New sort options in `getSortColumn`: `familiarity` (familiarity_rating), `comms_recency` (comms_last_date)
- Default sort changed from `ai_proximity_score` to `familiarity_rating` with `comms_last_date DESC NULLS LAST` as secondary
- Updated `applyPostFilters` for hybrid search path with same familiarity_min, has_comms, comms_since filters
- Updated `searchNetwork` tool in network-tools.ts:
  - Added `familiarity_min`, `has_comms`, `comms_since`, `sort_by` parameters to tool definition
  - Marked `proximity_min` as legacy in description
  - Updated implementation with new filter handlers and sort logic
  - Default sort now familiarity_rating DESC with comms_last_date DESC as secondary
- TypeScript compiles cleanly (`npx tsc --noEmit` passes)

**Learnings:**
- Supabase JS client doesn't support JSONB path ordering (e.g., `ask_readiness->outdoorithm_fundraising->>'score'`), so ask_readiness sorting requires fetching extra rows and sorting in-memory. The approach fetches `limit * 2` rows and sorts/slices in JS.
- The `nullsFirst: false` option in Supabase's `.order()` is important for familiarity_rating and comms_last_date since many contacts have NULL values — without it, NULLs sort first in DESC order.
- The search_network tool in network-tools.ts (used by the agent) and the search route (used by the UI) have separate but parallel implementations. Both needed updating with the same filters.

## Iteration 10: US-010 — Add goal_search Tool
**Date:** 2026-02-20
**Status:** COMPLETE
**Commit:** daf7c41

**What was done:**
- Added `goal_search` tool definition to the `networkTools` array in `network-tools.ts`
  - Parameters: goal (enum: outdoorithm_fundraising, kindora_sales), tier filter (ready_now/cultivate_first/long_term/not_a_fit/all), min_familiarity, limit
  - Description explains this is the primary tool for fundraising/outreach planning queries
- Added `goalSearch` implementation function:
  - Queries contacts where `ask_readiness` IS NOT NULL
  - Filters in JS by goal key presence and tier (Supabase can't filter JSONB nested keys easily)
  - Sorts by `ask_readiness[goal].score` DESC in JS (Supabase can't sort by JSONB nested path)
  - Over-fetches (limit * 3) to compensate for in-JS filtering
  - Returns flattened response with ask_readiness fields inline: score, tier, reasoning, recommended_approach, ask_timing, cultivation_needed, suggested_ask_range, personalization_angle, risk_factors
  - Also includes shared_institutions and communication_history in the fetch for richer context
- Added `goal_search` case to `executeNetworkToolCall` switch statement
- No changes needed to `route.ts` — it already dispatches all tools generically through `executeNetworkToolCall`
- TypeScript compiles cleanly

**Learnings:**
- The route.ts agent dispatch loop is already generic — it passes all tool calls through `executeNetworkToolCall`, so adding a new tool only requires changes to `network-tools.ts` (definition + implementation + switch case). No route.ts changes needed.
- The goal_search response flattens ask_readiness fields inline per contact (ask_readiness_score, ask_readiness_tier, reasoning, etc.) rather than nesting them. This makes the data more readable in the agent's tool result context and avoids the agent needing to navigate nested JSONB.
- Over-fetching by 3x (limit * 3) is needed because the initial query can't filter by specific goal key — we fetch contacts with any ask_readiness data and then filter in JS. This is acceptable since the dataset is small (~2,400 contacts max).

## Iteration 11: US-011 — Update Agent System Prompt
**Date:** 2026-02-20
**Status:** COMPLETE

**What was done:**
- Rewrote `SYSTEM_PROMPT` in `job-matcher-ai/app/api/network-intel/route.ts`
- Primary signal section: Familiarity Rating (0-4) with clear descriptions of each level
- Communication History section: explains comms_last_date and comms_thread_count fields, what they signal
- Ask-Readiness Scoring section: full explanation of tiers (ready_now, cultivate_first, long_term, not_a_fit) with score ranges, plus all output fields (reasoning, recommended_approach, suggested_ask_range, personalization_angle, risk_factors)
- Supplementary Scores section: capacity, kindora, outdoorithm fit retained; proximity explicitly marked as "Legacy AI-estimated closeness — superseded by familiarity rating"
- Wealth Signals section: mentions FEC donations and real estate holdings as available data
- Tool Usage Strategy updated: goal_search is listed FIRST for fundraising/outreach queries with "CRITICAL" instruction to always use it first
- Result Formatting updated: familiarity (0-4) replaces proximity tier; fundraising results should include tier, score, range, and reasoning
- TypeScript compiles cleanly

**Learnings:**
- The system prompt is a pure string constant — no TypeScript types or interfaces involved, so the change is low-risk and doesn't affect compilation.
- Kept the ABOUT JUSTIN section unchanged since it's factual and still accurate.
- The prompt is now ~2x longer than before but well within context limits for claude-sonnet-4-6 (16K max_tokens output, system prompt is ~2K tokens).
- Preserved all existing tool usage patterns (semantic_search, hybrid_search, find_similar, export_contacts) — just reordered to put goal_search first for fundraising queries.

